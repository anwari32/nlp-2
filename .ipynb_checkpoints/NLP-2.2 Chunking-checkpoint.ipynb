{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "turkish-share",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Load GloVe model\n",
    "GLOVE_PATH = \"glove.6B.50d.txt\"\n",
    "EMBEDDING_DIM = 50\n",
    "\n",
    "def load_word_vectors(path):\n",
    "    word_vectors = dict()\n",
    "    f = open(path, encoding=\"utf-8\")\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        word_numbers = values[1:]\n",
    "        word_vectors[word] = word_numbers\n",
    "    f.close()\n",
    "    print(\"load {} word vectors.\".format(len(word_vectors)))\n",
    "    return word_vectors\n",
    "\n",
    "word_vectors = load_word_vectors(GLOVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fabulous-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"train.txt/train.csv\", encoding=\"utf-8\")\n",
    "test_data = pd.read_csv(\"test.txt/test.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "molecular-attendance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Confidence</td>\n",
       "      <td>NN</td>\n",
       "      <td>B-NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>B-PP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>B-NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pound</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>B-VP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>widely</td>\n",
       "      <td>RB</td>\n",
       "      <td>I-VP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expected</td>\n",
       "      <td>VBN</td>\n",
       "      <td>I-VP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>I-VP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>take</td>\n",
       "      <td>VB</td>\n",
       "      <td>I-VP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>another</td>\n",
       "      <td>DT</td>\n",
       "      <td>B-NP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word  POS   Tag\n",
       "0  Confidence   NN  B-NP\n",
       "1          in   IN  B-PP\n",
       "2         the   DT  B-NP\n",
       "3       pound   NN  I-NP\n",
       "4          is  VBZ  B-VP\n",
       "5      widely   RB  I-VP\n",
       "6    expected  VBN  I-VP\n",
       "7          to   TO  I-VP\n",
       "8        take   VB  I-VP\n",
       "9     another   DT  B-NP"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.fillna(method=\"ffill\")\n",
    "test_data = test_data.fillna(method=\"ffill\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cross-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(data[\"Word\"].values))\n",
    "test_words = list(set(test_data[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "test_words.append(\"ENDPAD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "complimentary-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = list(set(data[\"Tag\"].values))\n",
    "test_tags = list(set(test_data[\"Tag\"].values))\n",
    "# tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "critical-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "third-excuse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_words 19069, n_tags 22\n"
     ]
    }
   ],
   "source": [
    "n_words = len(words)\n",
    "n_tags = len(tags)\n",
    "print('n_words {}, n_tags {}'.format(n_words,n_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "finnish-paint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sentences : 8448\n",
      "# test sentences : 1883\n"
     ]
    }
   ],
   "source": [
    "# Grouping words into sentence.\n",
    "# Input : dataframe\n",
    "# Output : array of sentences.\n",
    "def group_words(df):\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    sentence_counter = 1\n",
    "    sentence_ending_counter = 0\n",
    "    for index, row in df.iterrows():\n",
    "        tuple = (row['Word'],row['POS'],row['Tag'])\n",
    "\n",
    "        sentence.append(tuple)\n",
    "        if (row['Word'] == '.' and row['POS'] == '.' and row['Tag'] == 'O'):\n",
    "            sentence_ending_counter += 1\n",
    "        \n",
    "        if (sentence_ending_counter > 1):\n",
    "            sentences.append(sentence)                \n",
    "            sentence_ending_counter = 0\n",
    "            sentence = []\n",
    "                            \n",
    "    return sentences\n",
    "    \n",
    "sentences = group_words(data)\n",
    "test_sentences = group_words(test_data)\n",
    "print(\"# sentences : {}\".format(len(sentences)))\n",
    "print(\"# test sentences : {}\".format(len(test_sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "signed-change",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.hist([len(s) for s in sentences], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fifty-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "test_word2idx = {w: i for i, w in enumerate(test_words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "test_tag2idx = {t: i for i, t in enumerate(test_tags)}\n",
    "# word2idx.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "committed-active",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17124"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx[\"Confidence\"]\n",
    "# test_word2idx[\"Confidence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ideal-moisture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx[\"B-NP\"]\n",
    "test_tag2idx[\"B-NP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "geographic-titanium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.19825 , -1.4242  ,  0.7066  , ...,  0.17844 ,  1.2384  ,\n",
       "        -0.73137 ],\n",
       "       [ 0.9832  , -0.10158 ,  0.16328 , ...,  1.3028  ,  0.010852,\n",
       "        -0.60187 ],\n",
       "       [ 0.47343 , -0.89558 ,  1.6287  , ..., -0.072221, -0.45994 ,\n",
       "         0.20228 ],\n",
       "       ...,\n",
       "       [-0.3708  ,  0.27284 , -0.36559 , ...,  0.51418 , -0.3504  ,\n",
       "        -0.094215],\n",
       "       [ 0.7048  ,  0.22261 ,  0.086997, ..., -0.39688 ,  0.17632 ,\n",
       "         0.31862 ],\n",
       "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
       "         0.      ]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_embedding_matrix(word_index):\n",
    "    vocabulary_size = len(word_index)\n",
    "    embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n",
    "    for word,i in word_index.items():\n",
    "        try:\n",
    "            # print('word[{}] => {}'.format(i,word))\n",
    "            embedding_vector = word_vectors[word]\n",
    "            embedding_matrix[i] = np.array(embedding_vector)\n",
    "        except KeyError:\n",
    "            vec = np.zeros(EMBEDDING_DIM)\n",
    "            embedding_matrix[i] = vec\n",
    "    return embedding_matrix\n",
    "\n",
    "embedding_matrix = create_embedding_matrix(word2idx)\n",
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "lovely-hudson",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'\\ufeffRockwell'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-c9b7c11f5ab3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_sentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_words\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_words\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-c9b7c11f5ab3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_sentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_words\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_words\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-c9b7c11f5ab3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_sentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_words\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_words\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '\\ufeffRockwell'"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X_test = [[word2idx[w[0]] for w in s] for s in test_sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=n_words - 1)\n",
    "X_test = pad_sequences(maxlen=max_len, sequences=X_test, padding=\"post\", value=n_words - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "large-recommendation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17124, 12240, 11067, ..., 19068, 19068, 19068],\n",
       "       [ 5310, 18346, 11067, ..., 19068, 19068, 19068],\n",
       "       [12475,  6709, 15577, ..., 19068, 19068, 19068],\n",
       "       ...,\n",
       "       [ 7279, 15195,  5360, ..., 19068, 19068, 19068],\n",
       "       [ 7279,  6581,  5360, ..., 19068, 19068, 19068],\n",
       "       [ 7279,  8338, 13395, ..., 19068, 19068, 19068]], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dangerous-hawaiian",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
    "y_test = [[tag2idx[w[2]] for w in s] for s in test_sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n",
    "y_test = pad_sequences(maxlen=max_len, sequences=y_test, padding=\"post\", value=tag2idx[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "extensive-modem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  2,  6, ..., 16, 16, 16],\n",
       "       [16,  2,  6, ..., 16, 16, 16],\n",
       "       [16,  6, 12, ..., 16, 16, 16],\n",
       "       ...,\n",
       "       [16,  6,  0, ..., 16, 16, 16],\n",
       "       [16,  6,  0, ..., 16, 16, 16],\n",
       "       [16,  6, 12, ..., 16, 16, 16]], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "assumed-fusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y = [to_categorical(i, num_classes=n_tags) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aerial-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_training, X_validation, y_training, y_validation = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "processed-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Conv1D, MaxPooling1D,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "retired-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(max_len,))\n",
    "model = Embedding(input_dim=n_words, output_dim=EMBEDDING_DIM, input_length=max_len, weights=[embedding_matrix])(input)  # 50-dim embedding\n",
    "model = Conv1D(128, 5, activation='relu', padding=\"same\")(model) # padding = same so that conv-result doesn't change. (why?)\n",
    "# model = MaxPooling1D(5)(model)\n",
    "model = Dropout(0.1)(model)\n",
    "model = Bidirectional(LSTM(units=128, return_sequences=True, recurrent_dropout=0.1))(model)  # variational biLSTM\n",
    "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(model)  # softmax output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "binding-enhancement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 50, 50)            953450    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 50, 128)           32128     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 50, 256)           263168    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 50, 22)            5654      \n",
      "=================================================================\n",
      "Total params: 1,254,400\n",
      "Trainable params: 1,254,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(input, out)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "parental-maldives",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "214/214 [==============================] - 34s 142ms/step - loss: 0.7806 - accuracy: 0.7660 - val_loss: 0.2468 - val_accuracy: 0.9270\n",
      "Epoch 2/3\n",
      "214/214 [==============================] - 30s 140ms/step - loss: 0.2320 - accuracy: 0.9302 - val_loss: 0.1639 - val_accuracy: 0.9500\n",
      "Epoch 3/3\n",
      "214/214 [==============================] - 30s 140ms/step - loss: 0.1549 - accuracy: 0.9532 - val_loss: 0.1390 - val_accuracy: 0.9583\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_training, np.array(y_training), batch_size=32, epochs=3, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-approach",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss,train_accuracy = model.evaluate(X_training, y_training, verbose=False)\n",
    "print(\"validation accuracy: {:.4f}\".format(valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_training, y_training, epochs=3, verbose=1, validation_data=[X_validation,y_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss,test_accuracy = model.evaluate(X_test, Y_test, verbose=False)\n",
    "print(\"test accuracy: {:.4f}\".format(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
